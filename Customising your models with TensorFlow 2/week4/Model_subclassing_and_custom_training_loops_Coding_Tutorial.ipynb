{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Coding Tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmed-gharib89/TensorFlow_2_for_Deep_Learning/blob/master/Customising%20your%20models%20with%20TensorFlow%202/week4/Model_subclassing_and_custom_training_loops_Coding_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHzMiEi3i3HV"
      },
      "source": [
        "#! pip install tensorflow==2.1.0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4ZOwI8nhm6n",
        "outputId": "54ef64f4-ae9a-4fa9-a3bd-8cfd3bcc344c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do78XVSShm6y"
      },
      "source": [
        "# Model subclassing and custom training loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Bw0G6ZUhm60"
      },
      "source": [
        " ## Coding tutorials\n",
        " #### [1. Model subclassing](#coding_tutorial_1)\n",
        " #### [2. Custom layers](#coding_tutorial_2)\n",
        " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
        " #### [4. Custom training loops](#coding_tutorial_4)\n",
        " #### [5. tf.function decorator](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsqxoGq1hm61"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## Model subclassing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq6q5LEXhm63"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g03dxofchm6_"
      },
      "source": [
        "#### Create a simple model using the model subclassing API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy7qb3k4hm7B"
      },
      "source": [
        "# Build the model\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.dense_1 = Dense(64, activation='relu')\n",
        "        self.dense_2 = Dense(10)\n",
        "        self.dense_3 = Dense(5)\n",
        "        self.softmax = Softmax()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense_1(inputs)\n",
        "        y1 = self.dense_2(inputs)\n",
        "        y2 = self.dense_3(y1)\n",
        "        concat = concatenate([x, y2])\n",
        "        return self.softmax(concat)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jra1OIchm7I",
        "outputId": "43f060ad-89c6-4766-b51a-1a3324f09442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Print the model summary\n",
        "\n",
        "model = MyModel()\n",
        "model(tf.random.uniform([1, 10]))\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              multiple                  704       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             multiple                  110       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             multiple                  55        \n",
            "_________________________________________________________________\n",
            "softmax_1 (Softmax)          multiple                  0         \n",
            "=================================================================\n",
            "Total params: 869\n",
            "Trainable params: 869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLCjbBfNhm7R"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77Y_mI1yhm7S"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX4uWr50hm7Y"
      },
      "source": [
        "#### Create custom layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByEu6yshhm7Z",
        "outputId": "a4b2a670-cff9-413a-bb24-2832c1e373fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "# Create a custom layer\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyLayer, self).__init__()\n",
        "        self.w = self.add_weight(shape=(input_dim, units),\n",
        "                                 initializer='random_normal')\n",
        "        self.b = self.add_weight(shape=(units, ),\n",
        "                                 initializer='zeros')\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "dense_layer = MyLayer(3, 5)        \n",
        "x = tf.ones((1, 5))\n",
        "print(dense_layer(x))\n",
        "print(dense_layer.weights)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[ 0.21409503 -0.13026221 -0.10861768]], shape=(1, 3), dtype=float32)\n",
            "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
            "array([[ 0.0658439 , -0.00135116, -0.01763991],\n",
            "       [ 0.02475345,  0.01477749, -0.02598752],\n",
            "       [-0.01137382, -0.04443141, -0.08959068],\n",
            "       [ 0.20106196, -0.01637762,  0.02889025],\n",
            "       [-0.06619047, -0.08287951, -0.00428981]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivgvgoo2hm7f"
      },
      "source": [
        "# Specify trainable weights\n",
        "\n",
        "class MyLayer(Layer):\n",
        "\n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyLayer, self).__init__()\n",
        "        self.w = self.add_weight(shape=(input_dim, units),\n",
        "                                 initializer='random_normal',\n",
        "                                 trainable=False)\n",
        "        self.b = self.add_weight(shape=(units, ),\n",
        "                                 initializer='zeros',\n",
        "                                 trainable=False)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "dense_layer = MyLayer(3, 5)  "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n1_RMT8hm7k",
        "outputId": "5eb59e2d-d6b6-49dc-d609-2005161d6e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('trainable weights:', len(dense_layer.trainable_weights))\n",
        "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainable weights: 0\n",
            "non-trainable weights: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRSEgfrRhm7p"
      },
      "source": [
        "# Create a custom layer to accumulate means of output values\n",
        "\n",
        "class MyLayerMean(Layer):\n",
        "\n",
        "    def __init__(self, units, input_dim):\n",
        "        super(MyLayerMean, self).__init__()\n",
        "        self.w = self.add_weight(shape=(input_dim, units),\n",
        "                                 initializer='random_normal')\n",
        "        self.b = self.add_weight(shape=(units, ),\n",
        "                                 initializer='zeros')\n",
        "        self.sum_activation = tf.Variable(initial_value=tf.zeros((units, )),\n",
        "                                          trainable=False)\n",
        "        self.number_call = tf.Variable(initial_value=0,\n",
        "                                          trainable=False)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        activation = tf.matmul(inputs, self.w) + self.b\n",
        "        self.sum_activation.assign_add(tf.reduce_sum(activation, axis=0))\n",
        "        self.number_call.assign_add(inputs.shape[0])\n",
        "        return activation, self.sum_activation / tf.cast(self.number_call, tf.float32)\n",
        "\n",
        "dense_layer = MyLayerMean(3, 5)  "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcj7_E7Ghm7u",
        "outputId": "46a3cccb-f00e-47ef-aea0-af9efe7f0bae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Test the layer\n",
        "\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())\n",
        "\n",
        "y, activation_means = dense_layer(tf.ones((1, 5)))\n",
        "print(activation_means.numpy())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.09921888 -0.10658434  0.04731317]\n",
            "[ 0.09921888 -0.10658434  0.04731317]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSb6tl9Hhm70"
      },
      "source": [
        "# Create a Dropout layer as a custom layer\n",
        "\n",
        "class MyDropout(Layer):\n",
        "\n",
        "    def __init__(self, rate):\n",
        "        super(MyDropout, self).__init__()\n",
        "        self.rate = rate\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass for dropout layer\n",
        "        return tf.nn.dropout(inputs, self.rate)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOWjEWRdhm75"
      },
      "source": [
        "#### Implement the custom layers into a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDJqxtMWhm76"
      },
      "source": [
        "# Build the model using custom layers with the model subclassing API\n",
        "\n",
        "class MyModel(Model):\n",
        "\n",
        "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
        "        super(MyModel, self).__init__()\n",
        "        # Define layers\n",
        "        self.layer_1 = MyLayer(units_1, input_dim_1)\n",
        "        self.dropout_1 = MyDropout(0.5)\n",
        "        self.layer_2 = MyLayer(units_2, units_1)\n",
        "        self.dropout_2 = MyDropout(0.5)\n",
        "        self.layer_3 = MyLayer(units_3, units_2)\n",
        "        self.softmax = Softmax()\n",
        "           \n",
        "    def call(self, inputs):\n",
        "        # Define forward pass\n",
        "        x = self.layer_1(inputs)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        \n",
        "        return self.softmax(x)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1SbtWqShm8A",
        "outputId": "b8a1ded2-d321-49f4-e6da-bba9ef6a23ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "source": [
        "# Instantiate a model object\n",
        "\n",
        "model = MyModel(64,10000,64,46)\n",
        "print(model(tf.ones((1, 10000))))\n",
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.01164976 0.02884148 0.03784274 0.01550604 0.02675365 0.02195023\n",
            "  0.00555709 0.00716725 0.00697773 0.00333357 0.00623146 0.00432402\n",
            "  0.00676593 0.0033841  0.0317387  0.01800704 0.12893122 0.01263592\n",
            "  0.00482962 0.00276647 0.12884709 0.02624645 0.01734837 0.01658681\n",
            "  0.02446243 0.05950272 0.02621106 0.03691554 0.04495729 0.00452474\n",
            "  0.01165697 0.01271167 0.01617803 0.0025196  0.02848419 0.00455557\n",
            "  0.0233422  0.00338983 0.00780473 0.0085161  0.05233975 0.02401256\n",
            "  0.00155038 0.00665741 0.01143313 0.01405133]], shape=(1, 46), dtype=float32)\n",
            "Model: \"my_model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "my_layer_5 (MyLayer)         multiple                  640064    \n",
            "_________________________________________________________________\n",
            "my_dropout_2 (MyDropout)     multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_6 (MyLayer)         multiple                  4160      \n",
            "_________________________________________________________________\n",
            "my_dropout_3 (MyDropout)     multiple                  0         \n",
            "_________________________________________________________________\n",
            "my_layer_7 (MyLayer)         multiple                  2990      \n",
            "_________________________________________________________________\n",
            "softmax_3 (Softmax)          multiple                  0         \n",
            "=================================================================\n",
            "Total params: 647,214\n",
            "Trainable params: 0\n",
            "Non-trainable params: 647,214\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr-3truQhm8F"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## Automatic differentiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4wmCC0Chm8G"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k1Sep_Ihm8L"
      },
      "source": [
        "#### Create synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V02wT1ANhm8M",
        "outputId": "c917f156-77f5-4027-cc70-7a030bda910f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# Create data from a noise contaminated linear model\n",
        "\n",
        "def MakeNoisyData(m, b, n=20):\n",
        "    x = tf.random.uniform(shape=(n,))\n",
        "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
        "    y = m * x + b + noise\n",
        "    return x, y\n",
        "\n",
        "m=1\n",
        "b=2\n",
        "x_train, y_train = MakeNoisyData(m,b)\n",
        "plt.plot(x_train, y_train, 'b.')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa44a3415f8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MwNGBd1hm8U"
      },
      "source": [
        "#### Define a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28aiwvOxhm8V"
      },
      "source": [
        "from tensorflow.keras.layers import Layer"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI2verfuhm8b",
        "outputId": "bf58d139-2856-4ce3-8bc9-71d18df6c2dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Build a custom layer for the linear regression model\n",
        "\n",
        "class LinearLayer(Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LinearLayer, self).__init__()\n",
        "        self.m = self.add_weight(shape=(1, ),\n",
        "                                 initializer = 'random_normal')\n",
        "        self.b = self.add_weight(shape=(1, ),\n",
        "                                 initializer = 'zeros')\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        return self.m * inputs + self.b\n",
        "\n",
        "linear_regression = LinearLayer()\n",
        "\n",
        "print(linear_regression(x_train))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[-0.01664756 -0.01423699 -0.0157434  -0.01537639 -0.01672869 -0.00188783\n",
            " -0.02123656 -0.00088388 -0.00947113 -0.01845683 -0.00292746 -0.00661529\n",
            " -0.00815281 -0.01758712 -0.02079771 -0.00762477 -0.00962539 -0.00242248\n",
            " -0.0117509  -0.02112353], shape=(20,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDa988kGhm8h"
      },
      "source": [
        "#### Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzb47kLBhm8i",
        "outputId": "40dff4fd-894d-46e3-960e-d8a5d77468ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Define the mean squared error loss function\n",
        "\n",
        "def SquaredError(y_pred, y_true):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
        "\n",
        "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
        "print(\"Starting loss\", starting_loss.numpy())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting loss 6.5978866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLahKHpmhm8n"
      },
      "source": [
        "#### Train and plot the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMTJx_gchm8o",
        "outputId": "3112d9f1-12d3-4b65-f6ce-e3a9aa926383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "# Implement a gradient descent training loop for the linear regression model\n",
        "\n",
        "learning_rate = 0.05\n",
        "steps = 50\n",
        "\n",
        "for i in range(steps):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = linear_regression(x_train)\n",
        "        loss = SquaredError(predictions, y_train)\n",
        "    \n",
        "    gradients = tape.gradient(loss, linear_regression.trainable_variables)\n",
        "    \n",
        "    linear_regression.m.assign_sub(learning_rate * gradients[0])\n",
        "    linear_regression.b.assign_sub(learning_rate * gradients[1])\n",
        "\n",
        "    print('Step %d, Loss %f' % (i, loss.numpy()))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0, Loss 0.010306\n",
            "Step 1, Loss 0.009016\n",
            "Step 2, Loss 0.008046\n",
            "Step 3, Loss 0.007316\n",
            "Step 4, Loss 0.006767\n",
            "Step 5, Loss 0.006353\n",
            "Step 6, Loss 0.006041\n",
            "Step 7, Loss 0.005806\n",
            "Step 8, Loss 0.005629\n",
            "Step 9, Loss 0.005494\n",
            "Step 10, Loss 0.005393\n",
            "Step 11, Loss 0.005315\n",
            "Step 12, Loss 0.005256\n",
            "Step 13, Loss 0.005211\n",
            "Step 14, Loss 0.005176\n",
            "Step 15, Loss 0.005149\n",
            "Step 16, Loss 0.005128\n",
            "Step 17, Loss 0.005112\n",
            "Step 18, Loss 0.005098\n",
            "Step 19, Loss 0.005087\n",
            "Step 20, Loss 0.005079\n",
            "Step 21, Loss 0.005071\n",
            "Step 22, Loss 0.005065\n",
            "Step 23, Loss 0.005059\n",
            "Step 24, Loss 0.005054\n",
            "Step 25, Loss 0.005050\n",
            "Step 26, Loss 0.005046\n",
            "Step 27, Loss 0.005042\n",
            "Step 28, Loss 0.005039\n",
            "Step 29, Loss 0.005035\n",
            "Step 30, Loss 0.005032\n",
            "Step 31, Loss 0.005029\n",
            "Step 32, Loss 0.005026\n",
            "Step 33, Loss 0.005023\n",
            "Step 34, Loss 0.005021\n",
            "Step 35, Loss 0.005018\n",
            "Step 36, Loss 0.005015\n",
            "Step 37, Loss 0.005013\n",
            "Step 38, Loss 0.005010\n",
            "Step 39, Loss 0.005007\n",
            "Step 40, Loss 0.005005\n",
            "Step 41, Loss 0.005002\n",
            "Step 42, Loss 0.005000\n",
            "Step 43, Loss 0.004998\n",
            "Step 44, Loss 0.004995\n",
            "Step 45, Loss 0.004993\n",
            "Step 46, Loss 0.004991\n",
            "Step 47, Loss 0.004988\n",
            "Step 48, Loss 0.004986\n",
            "Step 49, Loss 0.004984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wuw34zBhm8t",
        "outputId": "2709bc93-4919-48dc-e9ee-ef43033bb5ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "# Plot the learned regression model\n",
        "\n",
        "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
        "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
        "\n",
        "plt.plot(x_train, y_train, 'b.')\n",
        "\n",
        "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
        "plt.plot(x_linear_regression, linear_regression.m*x_linear_regression+linear_regression.b, 'r.')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m:1,  trained m:[1.0924592]\n",
            "b:2,  trained b:[1.9253473]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa449deb7b8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi9B9iWGhm8y"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## Custom training loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k44rXlNDhm8z"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrCFbxT_hm85"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdngimLwhm86"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKWXfry6hm8_"
      },
      "source": [
        "# Define the custom layers and model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDqc4hwphm9G"
      },
      "source": [
        "#### Load the reuters dataset and define the class_names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxVmj_vXhm9H"
      },
      "source": [
        "# Load the dataset\n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
        "\n",
        "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
        "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
        "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
        "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aByKDq7fhm9M"
      },
      "source": [
        "# Print the class of the first sample\n",
        "\n",
        "print(\"Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKnAWW09hm9R"
      },
      "source": [
        "#### Get the dataset word index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un9yoeH5hm9S"
      },
      "source": [
        "# Load the Reuters word index\n",
        "\n",
        "word_to_index = reuters.get_word_index()\n",
        "\n",
        "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
        "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1zY-ZiShm9W"
      },
      "source": [
        "# Print the first data example sentence\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTua_RJFhm9b"
      },
      "source": [
        "#### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVyzhoghhm9d"
      },
      "source": [
        "# Define a function that encodes the data into a 'bag of words' representation\n",
        "\n",
        "def bag_of_words(text_samples, elements=10000):\n",
        "    output = np.zeros((len(text_samples), elements))\n",
        "    for i, word in enumerate(text_samples):\n",
        "        output[i, word] = 1.\n",
        "    return output\n",
        "\n",
        "x_train = bag_of_words(train_data)\n",
        "x_test = bag_of_words(test_data)\n",
        "\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcTFArlnhm9j"
      },
      "source": [
        "#### Define the loss function and optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GvMepr2hm9k"
      },
      "source": [
        "# Define the categorical cross entropy loss and Adam optimizer\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "def loss(model, x, y, wd):\n",
        "    kernel_variables = []\n",
        "    for l in model.layers:\n",
        "        for w in l.weights:\n",
        "            if 'kernel' in w.name:\n",
        "                kernel_variables.append(w)\n",
        "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
        "    y_ = model(x)\n",
        "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ultdrCalhm9p"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-3Mx6NHhm9q"
      },
      "source": [
        "# Define a function to compute the forward and backward pass\n",
        "\n",
        "def grad(model, inputs, targets, wd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = loss(model, inputs, targets, wd)\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkp1ls32hm9t"
      },
      "source": [
        "# Implement the training loop\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "    \n",
        "    \n",
        "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07g_36Kfhm9x"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0XggoS0hm9y"
      },
      "source": [
        "# Create a Dataset object for the test set\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
        "test_dataset = test_dataset.batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5EXcq42hm93"
      },
      "source": [
        "# Collect average loss and accuracy\n",
        "\n",
        "epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU55_Ccthm97"
      },
      "source": [
        "# Loop over the test set and print scores\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "for x, y in test_dataset:\n",
        "    # Optimize the model\n",
        "    loss_value = loss(model, x, y, weight_decay)    \n",
        "    # Compute current loss\n",
        "    epoch_loss_avg(loss_value)  \n",
        "    # Compare predicted label to actual label\n",
        "    epoch_accuracy(to_categorical(y), model(x))\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
        "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFcunqd1hm9_"
      },
      "source": [
        "#### Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgtBziHrhm-A"
      },
      "source": [
        "# Plot the training loss and accuracy\n",
        "\n",
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8myoFZP1hm-E"
      },
      "source": [
        "#### Predict from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU5a2qdghm-F"
      },
      "source": [
        "# Get the model prediction for an example input\n",
        "\n",
        "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
        "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
        "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgPsEr8Ohm-K"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDWfa62_hm-L"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Softmax\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO9IMRHwhm-S"
      },
      "source": [
        "#### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNDJD9BVhm-T"
      },
      "source": [
        "# Initialize a new model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zilPIxYMhm-a"
      },
      "source": [
        "#### Redefine the grad function using the @tf.function decorator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFrYVoCphm-b"
      },
      "source": [
        "# Use the @tf.function decorator\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhwRfUFMhm-k"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg1NEtTghm-l"
      },
      "source": [
        "# Re-run the training loop\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO9MmJpHhm-p"
      },
      "source": [
        "#### Print the autograph code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cMMza5Ehm-q"
      },
      "source": [
        "# Use tf.autograph.to_code to see the generated code\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}